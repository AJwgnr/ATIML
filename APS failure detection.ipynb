{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Open Points:\n",
    "- How to deal with histogram data -> Currently each bin is seen as a feature\n",
    "- Try different feature selection/reduction techniques\n",
    "- Try different classification algorithms\n",
    "- include unbalancedness of classes in algorithm\n",
    "- Implement plotting of results as charts (http://scikit-learn.org/stable/modules/learning_curve.html)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabian/anaconda3/envs/ATIML/lib/python3.6/site-packages/pandas/core/nanops.py:358: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  the_mean = the_sum / count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       aa_000 ab_000      ac_000 ad_000 ae_000 af_000    ah_000 ai_000 aj_000  \\\n",
      "0       76698    NaN  2130706438    280      0      0   2551696      0      0   \n",
      "1       33058    NaN           0    NaN      0      0   1393352      0     68   \n",
      "2       41040    NaN         228    100      0      0   1234132      0      0   \n",
      "3          12      0          70     66      0     10      2668      0      0   \n",
      "4       60874    NaN        1368    458      0      0   1974038      0    226   \n",
      "5       38312    NaN  2130706432    218      0      0   1087760      0      0   \n",
      "6          14      0           6    NaN      0      0      2094      0      0   \n",
      "7      102960    NaN  2130706432    116      0      0   2738458      0      0   \n",
      "8       78696    NaN           0    NaN      0      0   3209768      0     80   \n",
      "9      153204      0         182    NaN      0      0   2658638  14346      0   \n",
      "10      39196    NaN         204    170      0      0   1055746   3320      0   \n",
      "11      45912    NaN           0    454      0      0   1434684      0      0   \n",
      "12       2104    NaN          36     26      0      0     59062      0      0   \n",
      "13     118950    NaN        1390   1298      0      0   3466260      0      0   \n",
      "14      24416    NaN           0    NaN      0      0    716912      0     64   \n",
      "15         14      0          62     34      0      0      2182      0      0   \n",
      "16      31300      0         784    740      0      0   4730560      0      0   \n",
      "17        736      2          24     22     16     20     17644      0      0   \n",
      "18        332    NaN  2130706432     20      0      0     11362      0      0   \n",
      "19       1432    NaN  2130706440     82      0      0     40250      0     58   \n",
      "20      41212      0  2130706434    104    104    172   1027430      0     32   \n",
      "21         14    NaN           6      6      0      0      2498      0      0   \n",
      "22     157128    NaN  2130706456    424      0      0   5287200      0      0   \n",
      "23     453236    NaN        2926    NaN      0      0  18489312  19038      0   \n",
      "24      58246    NaN  2130706432   2416      0      0   1706406      0      0   \n",
      "25      29394    NaN           0    NaN      0      0   1002966      0      0   \n",
      "26       8690    NaN         476    364      0      0    312268      0     64   \n",
      "27      46978    NaN         334    322      0      0   1453404      0      0   \n",
      "28       1870    NaN         NaN    NaN      0      0     35354      0      0   \n",
      "29      12516      0         120    NaN      0      0    562814      0      0   \n",
      "...       ...    ...         ...    ...    ...    ...       ...    ...    ...   \n",
      "59970      16      0           8    NaN      0      0      2660      0     68   \n",
      "59971   39026    NaN         202    168      0      0   1145836      0      0   \n",
      "59972      14    NaN          24     20      0      0      2096      0      0   \n",
      "59973    3248      8          16     10      0      0    123200      0      0   \n",
      "59974   83818    NaN         552    532      0      0   2164020      0      0   \n",
      "59975   40274    NaN          98     94      0      0   1082946      0      0   \n",
      "59976   16978    NaN  2130706434   1750      0      0    568700      0      0   \n",
      "59977   30320    NaN        1838   1278      0      0    946490      0      0   \n",
      "59978   38414    NaN         888    758      0      0   1776418      0     52   \n",
      "59979      18      0  2130706432     18      0      0      1134      0      0   \n",
      "59980     562      0           4      4      0      0     17764      0      0   \n",
      "59981      16    NaN          20     20      0      0      3148      0      0   \n",
      "59982   10628    NaN  2130706434     98      0      0    286330      0      0   \n",
      "59983   39004    NaN          90     84      0      0   1131314      0      0   \n",
      "59984   33386    NaN         812    744      0      0   1099804      0      0   \n",
      "59985   10792    NaN         784    608      0      0   1929640      0      0   \n",
      "59986     644    NaN          12    NaN      0      0     36800      0     72   \n",
      "59987   41330    NaN  2130706432    744      0      0   1530526      0      0   \n",
      "59988    6078    NaN          52     46      0      0    140374      0      0   \n",
      "59989   61478    NaN         134      0      0      0   1595330      0      0   \n",
      "59990   81354    NaN  2130706432    156      0      0   2070562      0      0   \n",
      "59991   39308    NaN         452    374      0      0   1238598      0      0   \n",
      "59992      14      0           2      2      0      0      2392      0      0   \n",
      "59993       0      2           0      0      0      0       554      0     36   \n",
      "59994      32      0           0    NaN      0      0      1984      0      0   \n",
      "59995  153002    NaN         664    186      0      0   4880368      0    280   \n",
      "59996    2286    NaN  2130706538    224      0      0     56982      0      0   \n",
      "59997     112      0  2130706432     18      0      0      8784      0      0   \n",
      "59998   80292    NaN  2130706432    494      0      0   2634394      0      0   \n",
      "59999   40222    NaN         698    628      0      0   1235850   1926    474   \n",
      "\n",
      "      ak_000      ...      ed_000 ef_000 eg_000       ag_mean       ay_mean  \\\n",
      "0          0      ...        2712      0      0  3.725014e+30  4.690144e+24   \n",
      "1          0      ...        2334      0      0  1.825465e+28  7.151077e+22   \n",
      "2          0      ...        1020      0      0  1.648371e+27  8.704562e+18   \n",
      "3          0      ...          54      4     32  3.182212e+16  2.038560e+07   \n",
      "4          0      ...        1176      0      0  4.375220e+28  4.212437e+29   \n",
      "5          0      ...        1100      0      0  9.128702e+29  2.801121e+24   \n",
      "6          0      ...          62      0      0  1.202377e+13  6.118000e+03   \n",
      "7          0      ...        2168      0      0  2.130142e+30  3.444416e+24   \n",
      "8          0      ...        2870      0      0  4.584407e+30  1.519812e+30   \n",
      "9          0      ...         166      0      0  1.180468e+23  9.418896e+10   \n",
      "10         0      ...        1234      0      0  4.352714e+25  5.406022e+18   \n",
      "11         0      ...        1870      0      0  2.106419e+30  9.733222e+24   \n",
      "12         0      ...         NaN      0      0  9.744131e+24  1.226013e+10   \n",
      "13         0      ...        4712      0      0  4.093217e+35  3.928635e+24   \n",
      "14         0      ...         NaN      0      0  5.564485e+24  3.472317e+21   \n",
      "15         0      ...          64      0      0  6.425622e+10  6.512000e+03   \n",
      "16         0      ...        3018      0      0  2.038685e+43  1.958837e+13   \n",
      "17         0      ...         124      0      0  1.144395e+19  2.046570e+08   \n",
      "18         0      ...          54      0      0  8.281822e+14  2.671414e+09   \n",
      "19         0      ...          68      0      0  7.817785e+15  5.357436e+10   \n",
      "20         0      ...        1244      0      0  9.268134e+25  2.299080e+17   \n",
      "21         0      ...          34      0      0  6.618444e+12  5.538000e+05   \n",
      "22         0      ...        4844      0      0  2.656834e+34  8.248804e+14   \n",
      "23       NaN      ...         NaN      0      0  2.223234e+42  2.273870e+63   \n",
      "24         0      ...        2700      0      0  1.271482e+30  7.013020e+24   \n",
      "25         0      ...         962      0      0  9.523342e+25  1.782426e+18   \n",
      "26         0      ...         452      0      0  6.021732e+20  1.302251e+21   \n",
      "27         0      ...        1696      0      0  5.500213e+32  1.468382e+24   \n",
      "28       NaN      ...         NaN      0      0  1.406882e+14  1.856759e+17   \n",
      "29         0      ...         768      0      0  2.188663e+23  4.966428e+11   \n",
      "...      ...      ...         ...    ...    ...           ...           ...   \n",
      "59970      0      ...          38      0      0  1.085176e+12  4.082344e+07   \n",
      "59971      0      ...        1490      0      0  2.150102e+27  6.542873e+21   \n",
      "59972      0      ...          36      0      0  4.439656e+10  6.038000e+03   \n",
      "59973      0      ...         388      0      0  9.046123e+26  3.742026e+10   \n",
      "59974      0      ...        2056      0      0  3.088213e+31  1.686428e+24   \n",
      "59975      0      ...         852      0      0  3.383730e+29  2.725014e+24   \n",
      "59976      0      ...         656      0      0  5.826225e+23  2.752455e+21   \n",
      "59977      0      ...         714      0      0  2.238676e+26  1.367611e+21   \n",
      "59978      0      ...        4672      0      0  4.154617e+29  5.829030e+22   \n",
      "59979      0      ...          50      0      0  3.656173e+13  3.616456e+07   \n",
      "59980      0      ...         140      0      0  1.153834e+15  2.003028e+09   \n",
      "59981      0      ...          54      0      0  9.013047e+13  6.214132e+10   \n",
      "59982      0      ...         300      0      0  4.868117e+29  3.661015e+46   \n",
      "59983      0      ...        1114      0      0  9.360209e+33  2.319502e+23   \n",
      "59984      0      ...        1384      0      0  1.147065e+31  9.452615e+23   \n",
      "59985      0      ...        2136      0      0  3.189466e+34  4.714239e+23   \n",
      "59986      0      ...         240      0      0  1.811844e+20  1.432891e+09   \n",
      "59987      0      ...        1904      0      0  3.215418e+28  1.392415e+19   \n",
      "59988      0      ...         124      0      0  7.622588e+21  1.068722e+16   \n",
      "59989      0      ...        1872      0      0  2.050244e+28  1.813522e+19   \n",
      "59990      0      ...        1962      0      0  6.204014e+33  3.423619e+24   \n",
      "59991      0      ...         884      0      0  3.564128e+30  1.938722e+24   \n",
      "59992      0      ...          42      0      0  4.083275e+15  1.030560e+07   \n",
      "59993      0      ...          52      0      0  1.417721e+11  8.941928e+06   \n",
      "59994      0      ...          30      0      0  1.440325e+11  1.320769e+07   \n",
      "59995      0      ...        2858      0      0  2.564591e+39  4.511425e+25   \n",
      "59996      0      ...          82      0      0  1.049919e+16  4.610991e+18   \n",
      "59997      0      ...         134      0      0  2.811592e+13  7.042245e+07   \n",
      "59998      0      ...        1908      0      0  3.302025e+32  1.197424e+20   \n",
      "59999      0      ...        1256      0      0  1.226463e+29  1.057021e+25   \n",
      "\n",
      "            az_mean       ba_mean       cn_mean       cs_mean       ee_mean  \n",
      "0      5.374211e+35  2.328746e+49  1.181961e+39  1.047612e+47  9.658662e+54  \n",
      "1      7.336781e+38  1.378576e+56  3.898644e+36  6.160796e+43  6.645048e+54  \n",
      "2      1.620116e+33  7.906907e+48  3.327612e+34  3.584501e+44  2.620325e+54  \n",
      "3      6.466915e+21  6.176340e+23  5.225442e+21  1.032625e+21  5.670157e+20  \n",
      "4      1.644363e+30  1.348578e+54  3.563789e+36  3.942521e+45  4.047409e+56  \n",
      "5      1.580681e+30  1.037373e+49  3.661713e+38  3.812531e+42  3.010785e+45  \n",
      "6      1.484142e+18  4.332646e+25  5.201144e+18  1.228202e+26  4.252156e+19  \n",
      "7      6.634641e+35  1.699220e+50  2.510017e+35  7.650951e+45  5.432949e+58  \n",
      "8      5.574117e+33  3.982850e+45  2.489814e+39  1.152613e+49  1.875574e+55  \n",
      "9      2.501632e+29  7.029942e+41  3.285411e+37  5.566212e+38  5.128783e+39  \n",
      "10     1.928397e+31  9.935865e+50  1.223021e+32  4.458530e+43  4.525543e+56  \n",
      "11     2.730974e+33  1.461665e+49  4.881288e+34  5.554747e+44  6.414687e+54  \n",
      "12     1.122104e+26  3.786030e+41  9.652318e+29  1.134608e+30  4.170415e+36  \n",
      "13     1.531625e+40  3.371364e+52  1.543196e+42  1.556618e+48  1.236230e+57  \n",
      "14     3.050126e+29  5.401063e+44  1.632788e+30  2.582281e+39  1.636782e+54  \n",
      "15     2.402849e+22  5.002448e+24  3.556208e+15  9.301013e+22  4.524158e+21  \n",
      "16     1.036430e+45  6.776298e+54  1.923652e+49  1.239815e+47  5.895398e+44  \n",
      "17     2.861723e+29  3.102898e+35  1.152118e+27  1.148404e+30  2.447041e+34  \n",
      "18     6.014304e+19  1.606286e+23  3.932116e+21  1.363248e+27  7.248665e+25  \n",
      "19     1.142232e+20  3.115442e+27  8.354581e+21  1.902285e+30  1.521811e+33  \n",
      "20     1.602120e+35  7.248908e+52  2.410293e+37  3.280279e+37  2.659863e+50  \n",
      "21     5.481838e+17  4.796557e+17  3.718160e+12  8.012815e+24  2.662280e+15  \n",
      "22     7.014223e+35  4.218518e+52  2.892843e+40  1.605623e+45  2.014620e+61  \n",
      "23     2.882833e+42  1.263014e+56  2.459852e+50  1.673834e+53  4.079752e+64  \n",
      "24     6.732160e+39  1.432138e+49  7.243811e+42  9.118124e+42  6.806130e+57  \n",
      "25     4.078159e+32  9.163003e+53  4.822685e+32  3.480304e+40  3.426103e+46  \n",
      "26     2.328200e+29  3.408321e+36  1.765435e+29  2.946176e+40  1.257162e+49  \n",
      "27     2.822125e+35  1.008561e+49  8.363281e+38  5.010612e+43  5.154325e+51  \n",
      "28     1.008665e+23  5.832038e+28  3.504070e+20  9.781667e+30  1.225211e+34  \n",
      "29     3.350869e+31  6.402982e+51  1.662975e+43  3.770324e+41  4.197503e+46  \n",
      "...             ...           ...           ...           ...           ...  \n",
      "59970  6.210145e+20  6.220264e+24  4.956167e+15  1.090101e+24  4.946230e+20  \n",
      "59971  2.262527e+32  1.043143e+44  1.849601e+36  4.542641e+44  3.862204e+54  \n",
      "59972  5.026366e+18  4.838478e+23  3.624433e+14  8.941620e+22  3.860170e+18  \n",
      "59973  3.674336e+35  1.272781e+40  5.232234e+34  1.970143e+38  1.242863e+42  \n",
      "59974  3.776142e+34  1.374736e+50  1.638124e+34  7.620108e+45  5.827881e+58  \n",
      "59975  1.290437e+31  8.704126e+48  2.503411e+35  2.924438e+42  2.714544e+52  \n",
      "59976  1.464121e+33  4.730523e+39  1.012635e+31  1.964232e+42  2.242302e+53  \n",
      "59977  1.038387e+29  7.657544e+42  1.548325e+35  2.418310e+40  2.506502e+55  \n",
      "59978  6.524198e+36  2.042289e+53  8.498354e+40  1.493223e+47  1.242492e+59  \n",
      "59979  7.238011e+22  5.858524e+27  3.196185e+20  2.082141e+23  5.224273e+20  \n",
      "59980  3.101626e+21  2.873293e+32  5.398144e+27  2.984496e+31  2.028065e+34  \n",
      "59981  9.762786e+23  7.982562e+22  9.266336e+15  9.726305e+25  6.656237e+20  \n",
      "59982  5.301742e+25  2.378785e+35  2.174220e+35  8.841345e+39  5.419465e+39  \n",
      "59983  1.854630e+34  8.055286e+51  4.838663e+36  3.810457e+43  4.196084e+57  \n",
      "59984  3.516150e+34  8.664465e+54  9.106473e+34  5.222636e+44  4.638325e+56  \n",
      "59985  3.310854e+35  3.514933e+44  1.426110e+43  6.366918e+42  3.394053e+50  \n",
      "59986  1.580214e+25  7.290625e+28  7.338475e+25  1.530643e+29  6.702294e+33  \n",
      "59987  6.130673e+35  1.899105e+45  1.364822e+38  6.364767e+45  1.103919e+51  \n",
      "59988  1.861242e+28  1.390921e+30  6.422105e+27  3.405813e+33  1.629035e+38  \n",
      "59989  3.266245e+36  1.791049e+43  1.254013e+35  6.164836e+43  4.313607e+50  \n",
      "59990  2.624129e+36  1.616900e+58  1.215275e+41  6.824732e+45  6.261527e+52  \n",
      "59991  1.296641e+32  7.801525e+47  2.145741e+35  3.002406e+43  2.586424e+56  \n",
      "59992  1.222237e+21  4.940575e+23  3.763172e+21  1.100121e+25  4.648162e+20  \n",
      "59993  1.154210e+17  1.990268e+19  8.241994e+10  1.080829e+16  2.782400e+12  \n",
      "59994  8.224323e+21  6.562881e+22  1.326684e+13  1.186168e+24  6.298144e+24  \n",
      "59995  7.620347e+33  3.245782e+54  8.601681e+45  1.245013e+49  1.608808e+62  \n",
      "59996  1.238283e+23  4.422861e+33  6.157264e+21  1.340324e+34  1.393415e+33  \n",
      "59997  7.825249e+26  1.854222e+29  3.956147e+17  1.034247e+25  1.587627e+28  \n",
      "59998  5.518409e+34  2.154166e+51  1.146076e+38  7.380868e+45  1.180714e+60  \n",
      "59999  3.298216e+34  1.035916e+50  3.249703e+31  4.526563e+42  4.097987e+55  \n",
      "\n",
      "[60000 rows x 107 columns]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import precision_score,classification_report,confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "#Data reaading parameter\n",
    "TEST_PATH ='dataset/aps_failure_test_set.csv'\n",
    "TRAIN_PATH ='dataset/aps_failure_training_set.csv'\n",
    "COLUMNS = ['aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000', 'af_000', 'ag_000', 'ag_001', 'ag_002', 'ag_003', 'ag_004', 'ag_005', 'ag_006', 'ag_007', 'ag_008', 'ag_009', 'ah_000', 'ai_000', 'aj_000', 'ak_000', 'al_000', 'am_0', 'an_000', 'ao_000', 'ap_000', 'aq_000', 'ar_000', 'as_000', 'at_000', 'au_000', 'av_000', 'ax_000', 'ay_000', 'ay_001', 'ay_002', 'ay_003', 'ay_004', 'ay_005', 'ay_006', 'ay_007', 'ay_008', 'ay_009', 'az_000', 'az_001', 'az_002', 'az_003', 'az_004', 'az_005', 'az_006', 'az_007', 'az_008', 'az_009', 'ba_000', 'ba_001', 'ba_002', 'ba_003', 'ba_004', 'ba_005', 'ba_006', 'ba_007', 'ba_008', 'ba_009', 'bb_000', 'bc_000', 'bd_000', 'be_000', 'bf_000', 'bg_000', 'bh_000', 'bi_000', 'bj_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'bs_000', 'bt_000', 'bu_000', 'bv_000', 'bx_000', 'by_000', 'bz_000', 'ca_000', 'cb_000', 'cc_000', 'cd_000', 'ce_000', 'cf_000', 'cg_000', 'ch_000', 'ci_000', 'cj_000', 'ck_000', 'cl_000', 'cm_000', 'cn_000', 'cn_001', 'cn_002', 'cn_003', 'cn_004', 'cn_005', 'cn_006', 'cn_007', 'cn_008', 'cn_009', 'co_000', 'cp_000', 'cq_000', 'cr_000', 'cs_000', 'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005', 'cs_006', 'cs_007', 'cs_008', 'cs_009', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000', 'dd_000', 'de_000', 'df_000', 'dg_000', 'dh_000', 'di_000', 'dj_000', 'dk_000', 'dl_000', 'dm_000', 'dn_000', 'do_000', 'dp_000', 'dq_000', 'dr_000', 'ds_000', 'dt_000', 'du_000', 'dv_000', 'dx_000', 'dy_000', 'dz_000', 'ea_000', 'eb_000', 'ec_00', 'ed_000', 'ee_000', 'ee_001', 'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008', 'ee_009', 'ef_000', 'eg_000']\n",
    "SKIPROWS = 20\n",
    "CLASS_NAMES = ['pos', 'neg']\n",
    "AG = np.array(['ag_000', 'ag_001', 'ag_002', 'ag_003', 'ag_004', 'ag_005', 'ag_006', 'ag_007', 'ag_008', 'ag_009'])\n",
    "AY = np.array(['ay_000', 'ay_001', 'ay_002', 'ay_003', 'ay_004', 'ay_005', 'ay_006', 'ay_007', 'ay_008', 'ay_009'])\n",
    "AZ = np.array(['az_000', 'az_001', 'az_002', 'az_003', 'az_004', 'az_005', 'az_006', 'az_007', 'az_008', 'az_009'])\n",
    "BA = np.array(['ba_000', 'ba_001', 'ba_002', 'ba_003', 'ba_004', 'ba_005', 'ba_006', 'ba_007', 'ba_008', 'ba_009'])\n",
    "CN = np.array(['cn_000', 'cn_001', 'cn_002', 'cn_003', 'cn_004', 'cn_005', 'cn_006', 'cn_007', 'cn_008', 'cn_009'])\n",
    "CS = np.array(['cs_000', 'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005', 'cs_006', 'cs_007', 'cs_008', 'cs_009'])\n",
    "EE = np.array(['ee_000', 'ee_001', 'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008', 'ee_009'])\n",
    "\n",
    "def meanHistograms():\n",
    "    # is a dataframe...\\n\",\n",
    "    data_set = loadDatasetWithPandas(TRAIN_PATH, SKIPROWS)\n",
    "    ag_ = data_set[AG]\n",
    "    ay_ = data_set[AY]\n",
    "    az_ = data_set[AZ]\n",
    "    ba_ = data_set[BA]\n",
    "    cn_ = data_set[CN]\n",
    "    cs_ = data_set[CS]\n",
    "    ee_ = data_set[EE]\n",
    "    \n",
    "    # create new dataframe for each of the above with the mean\\n\",\n",
    "    ag_mean = ag_.mean(axis=1, skipna=True)\n",
    "    ay_mean = ay_.mean(axis=1, skipna=True)\n",
    "    az_mean = az_.mean(axis=1, skipna=True)\n",
    "    ba_mean = ba_.mean(axis=1, skipna=True)\n",
    "    cn_mean = cn_.mean(axis=1, skipna=True)\n",
    "    cs_mean = cs_.mean(axis=1, skipna=True)\n",
    "    ee_mean = ee_.mean(axis=1, skipna=True)\n",
    "\n",
    "    remaining_columns = np.setdiff1d(np.setdiff1d(np.setdiff1d(np.setdiff1d(np.setdiff1d(np.setdiff1d(np.setdiff1d(np.array(COLUMNS), AG), AY), AZ), BA), CN), CS), EE)\n",
    "    remaining_data = data_set[remaining_columns]\n",
    "    return pd.concat(\n",
    "        [\n",
    "            remaining_data,\n",
    "            ag_mean.rename('ag_mean'),\n",
    "            ay_mean.rename('ay_mean'),\n",
    "            az_mean.rename('az_mean'),\n",
    "            ba_mean.rename('ba_mean'),\n",
    "            cn_mean.rename('cn_mean'),\n",
    "            cs_mean.rename('cs_mean'),\n",
    "            ee_mean.rename('ee_mean')\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "#Data preprocessing parameter\n",
    "NaNSTRATEGY = 'mean' #->'mean', 'median', 'most_frequent'\n",
    "\n",
    "\n",
    "def loadDatasetWithPandas(path,skiprowsNum):\n",
    "    #Reading the raw data from csv file\n",
    "    rawData = pd.read_csv(path,skiprows=skiprowsNum)\n",
    "    #display(rawData)  \n",
    "    #replacing the string indicating missing values with the numpy value for missing values\n",
    "    naNProcessedData = rawData.replace({'na': np.nan}, regex=True)\n",
    "    return naNProcessedData\n",
    "    \n",
    "    \n",
    "def processNaNInDataset(data, strategy):\n",
    "    values = data[list(COLUMNS)].values\n",
    "    imp = Imputer(missing_values='NaN', strategy=strategy, axis=0)\n",
    "    imp = imp.fit(values)\n",
    "    cleanedValues = imp.transform(values)\n",
    "    label = data['class'].values\n",
    "    return cleanedValues, label\n",
    "\n",
    "\n",
    "#processing pipeline (http://scikit-learn.org/stable/modules/pipeline.html#pipeline)\n",
    "def processingPipeline(featureReduction, featureSelector, classifier): \n",
    "    if(featureReduction == None):\n",
    "        if(featureSelector == None):\n",
    "            pipeline = make_pipeline(classifier)\n",
    "        else:\n",
    "            pipeline = make_pipeline(featureSelector,classifier)\n",
    "    else:\n",
    "        pipeline = make_pipeline(featureReduction, featureSelector,classifier)\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def findPipelineParameter(pipe):\n",
    "    #http://scikit-learn.org/stable/modules/grid_search.html\n",
    "    # search over whole parameter space of an estimator ->looks really interesting, but i dont´t have time right now to figure out how it works ;P\n",
    "    None\n",
    "    \n",
    "def testPipeline(pipeline,folds, metric):\n",
    "    #train\n",
    "    pipeline.fit(cleanedTrainValues, labelTrain)\n",
    "    #predict\n",
    "    predictions = pip.predict(cleanedTestValues)\n",
    "    #calculate cross validation according to given parameter\n",
    "    print(cross_val_score(pip, cleanedTestValues, labelTest, cv=folds , scoring=metric))\n",
    "    \n",
    "    #evaluation\n",
    "    evaluate(predictions)\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def evaluate(predictions):\n",
    "    classificationRep = classification_report(labelTest, predictions)\n",
    "    print(classificationRep)\n",
    "    \n",
    "    confusionMatrix = confusion_matrix(labelTest,predictions) \n",
    "    #print(confusionMatrix)\n",
    "    np.set_printoptions(precision=2)\n",
    "    #Code for plotting Confusion matrix\n",
    "    #####################\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(confusionMatrix, classes=CLASS_NAMES,\n",
    "                          title='Confusion matrix, without normalization')\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(confusionMatrix, classes=CLASS_NAMES, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "    plt.show()\n",
    "    #####################\n",
    "\n",
    "    print('Score: ' + str(calculateOverallCostFromConfusionMatrix(confusionMatrix)))\n",
    "\n",
    "def calculateOverallCostFromConfusionMatrix(confusionMatrix):\n",
    "    #cost function from description\n",
    "    score = confusionMatrix[0][1] * 500 + 10*confusionMatrix[1][1]\n",
    "    return score\n",
    "\n",
    "#example -> joblib.dump(clf, 'filename.pkl') \n",
    "def saveTrainedModel(model, path):\n",
    "    joblib.dump(model, path)\n",
    "    return\n",
    "\n",
    "def loadTrainedModel(path):\n",
    "    clf = joblib.load(path)\n",
    "    return clf\n",
    "\n",
    "#taken from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Data Loading and processing of NaN\n",
    "####################################################################\n",
    "#Load Train Dataset\n",
    "trainData = loadDatasetWithPandas(TRAIN_PATH, SKIPROWS)\n",
    "#Load Test Dataset\n",
    "testData = loadDatasetWithPandas(TEST_PATH, SKIPROWS)\n",
    "\n",
    "#TODO: Test which works best: \"mean\", \"median”, or “most_frequent\"\n",
    "cleanedTrainValues, labelTrain = processNaNInDataset(trainData,NaNSTRATEGY)\n",
    "cleanedTestValues, labelTest = processNaNInDataset(testData,NaNSTRATEGY)\n",
    "#####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree classifier\n",
    "#####################################################################\n",
    "\n",
    "#Tree parameter\n",
    "max_depth = 5\n",
    "min_samples_leaf = 20\n",
    "#min_samples_split =\n",
    "#class_weight ={0:.1, 1:.9}\n",
    "\n",
    "    \n",
    "decisiontree = tree.DecisionTreeClassifier(max_depth =max_depth, min_samples_leaf =min_samples_leaf)\n",
    "#Feature Selector\n",
    "for i in range(50,100):\n",
    "    print('Number of Features: ' + str(i))\n",
    "    featuresSelected = SelectKBest(chi2, k=i)\n",
    "    #feature reduction\n",
    "\n",
    "    #build pipelinee\n",
    "    pip = processingPipeline(None, featuresSelected,decisiontree)\n",
    "    \n",
    "    #evaluate pipeline\n",
    "    ##################################\n",
    "    #http://scikit-learn.org/stable/modules/model_evaluation.html -> available metrics\n",
    "    trainedPipe = testPipeline(pip,5,'accuracy')\n",
    "    \n",
    "\n",
    "#For generating the DT pdf later on\n",
    "#dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "#graph = graphviz.Source(dot_data) \n",
    "#graph.render(\"DT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "#-> Not reproducible results!!!!!\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "for  g in range(0,1):\n",
    "    randomfo = RandomForestClassifier(n_estimators=50)\n",
    "    #build pipelinee\n",
    "    pip = processingPipeline(None, None,randomfo)\n",
    "    #evaluate pipeline\n",
    "    trainedPip = testPipeline(pip,5,'accuracy')\n",
    "    \n",
    "saveTrainedModel(trainedPip, 'test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement SVM's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of loading a trained model\n",
    "pip  = loadTrainedModel('test.pkl')\n",
    "testPipeline(pip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
